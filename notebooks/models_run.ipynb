{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d952a0-9384-4a9e-884d-d2e6e0014d67",
   "metadata": {},
   "source": [
    "# Autoencoder asset pricing: A monte carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91d720d-5c36-4d0c-b650-9f06cf5262d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1065e4c4-09ff-4dcb-a770-eb8e79024550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from autoencoder import simulation as sim\n",
    "from autoencoder.training import run\n",
    "from autoencoder.networks import AE0, AE1, AE2, AE3\n",
    "from autoencoder.utils import (\n",
    "    split_dataset, torch_rolling_mean, AEDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2aa68f-2ea4-4748-affd-6880fdb354dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "bs = 1\n",
    "Ks = [3]\n",
    "model_ids = [3]\n",
    "models = {\n",
    "    0: AE0,\n",
    "    1: AE1,\n",
    "    2: AE2,\n",
    "    3: AE3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edceefe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps as device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f'Using {device} as device.')\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffbb5be-84c3-4a1a-982b-c00a2aedd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('usual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32378784-4555-4280-8ae7-26651c364aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(i):\n",
    "\n",
    "    model = models[model_id](sim.Pc, sim.Px, nb_factors).to(device)\n",
    "    nb, lb, nr, lr, nm, lm,  c, f = sim.simulate()\n",
    "    char_train, char_valid, char_tests = split_dataset(c)\n",
    "    if is_linear:\n",
    "        rets_train, rets_valid, rets_tests = split_dataset(lr)\n",
    "        port_train, port_valid, port_tests = split_dataset(lm)\n",
    "    \n",
    "    else:\n",
    "        rets_train, rets_valid, rets_tests = split_dataset(nr)\n",
    "        port_train, port_valid, port_tests = split_dataset(nm)\n",
    "    \n",
    "    train = DataLoader(\n",
    "        AEDataset(char_train, port_train, rets_train),\n",
    "        batch_size=bs,\n",
    "    )\n",
    "    \n",
    "    valid = DataLoader(\n",
    "        AEDataset(char_valid, port_valid, rets_valid),\n",
    "        batch_size=bs,\n",
    "    )\n",
    "    \n",
    "    char_tests = torch.tensor(char_tests).to(device)\n",
    "    rets_tests = torch.tensor(rets_tests).to(device)\n",
    "    port_tests = torch.tensor(port_tests).to(device)\n",
    "    # Train for each (model, number of factors) combinations\n",
    "    \n",
    "    \n",
    "    lp, lr = 1e-4, 1e-3\n",
    "    _, model, vl, tl, stop = run(model,\n",
    "                                 device,\n",
    "                                 train,\n",
    "                                 valid,\n",
    "                                 es_max_iter=20,\n",
    "                                 epochs=200,\n",
    "                                 lasso_param=lp,\n",
    "                                 learning_rate=lr)\n",
    "    \n",
    "    # title = f'Sim{1}+AC{model_id}+K={nb_factors}'\n",
    "    # plt.style.use('usual')\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.set_ylabel(f'Training Error: AE{model_id}(K={nb_factors})')\n",
    "    # ax.set_xlabel('Epochs')\n",
    "    # ax.plot(tl, label='Training', color='black')\n",
    "    # ax1 = plt.twinx()\n",
    "    # ax1.set_ylabel('Validation Error')\n",
    "    # ax1.plot(vl, label='Validation', color='red')\n",
    "    # if stop > 0:\n",
    "    #     ax1.axvline(stop, label='Early stopping', ls='--', color='blue')\n",
    "    # fig.legend(ncol=3, loc='upper center')\n",
    "    # fig.tight_layout()\n",
    "    # if is_linear:\n",
    "    #     fig.savefig(f'outputs/linear/{title}.pdf')\n",
    "    # else:\n",
    "    #     fig.savefig(f'outputs/non-linear/{title}.pdf')\n",
    "    # ax.clear()\n",
    "    # plt.close(fig)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        pred_tests = model(char_tests, port_tests)\n",
    "        out = pred_tests\n",
    "        rss = (pred_tests - rets_tests).pow(2).sum()\n",
    "        tss = rets_tests.pow(2).sum()\n",
    "        r2t = 1 - rss / tss\n",
    "        \n",
    "        factors = model.factors\n",
    "        betas = model.loadings[1:]\n",
    "        premias = torch_rolling_mean(factors, device)\n",
    "        pred_tests = torch.squeeze(betas @ premias)\n",
    "        out2 = pred_tests\n",
    "        rss = (pred_tests - rets_tests[1:]).pow(2).sum()\n",
    "        tss = rets_tests[1:].pow(2).sum()\n",
    "        r2p = 1 - rss / tss\n",
    "\n",
    "    return (model, r2t.item(), r2p.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3141be-2001-45d0-b0f7-862f3d273083",
   "metadata": {},
   "source": [
    "This part can be put in a loop but the hyperparameters tuning must be performed first and the appropriate hyperparameters should be used.\n",
    "Due to the time consuming part of hyperparameter tuning, I only heuristically tried to find the hyperparameters for the CA3 case with 3 factors. I also noticed that the model is quite sensitive to hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1414f1fd-00e1-4805-8b8b-3409b13570a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_linear = False\n",
    "model_id = 3\n",
    "nb_factors = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4877fad3-c1f5-42b9-a61e-790f51dc3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=4)(delayed(run_model)(i) for i in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e855129-a07d-48f0-bbf3-77c6924b4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for the model AE3 with K=3 are in the non-linear case\n",
      "Total R2 = 12.52\n",
      "Predictive R2 = 1.82\n"
     ]
    }
   ],
   "source": [
    "prdR2 = 0\n",
    "totR2 = 0\n",
    "for (r2t, r2p) in results:\n",
    "     totR2 += r2t\n",
    "     prdR2 += r2p\n",
    "\n",
    "\n",
    "print(f'The results for the model AE{model_id} with K={nb_factors} are in the non-linear case')\n",
    "print(f'Total R2 = {totR2:.2f}')\n",
    "print(f'Predictive R2 = {prdR2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ded85c74-e1f0-47ec-bcdb-1ba69ad41a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_linear = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf8e896-3bda-4826-bb2c-dd23db32101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=4)(delayed(run_model)(i) for i in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ecc524-e2b8-4b89-8beb-2b6948405946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for the model AE3 with K=3 are in the linear case:\n",
      "Total R2 = 26.84\n",
      "Predictive R2 = 4.24\n"
     ]
    }
   ],
   "source": [
    "prdR2 = 0\n",
    "totR2 = 0\n",
    "for (r2t, r2p) in results:\n",
    "     totR2 += r2t\n",
    "     prdR2 += r2p\n",
    "\n",
    "\n",
    "print(f'The results for the model AE{model_id} with K={nb_factors} are in the linear case:')\n",
    "print(f'Total R2 = {totR2:.2f}')\n",
    "print(f'Predictive R2 = {prdR2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de10e01-bfed-4460-8674-b8e3088cb664",
   "metadata": {},
   "source": [
    "WE obtain similar results as in the paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
